{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.appName(\"test\").master(\"local[4]\").config(\"spark.driver.memory\", \"4g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Using forward slashes for the path\n",
    "df = spark.read.csv(\"D:/STUFF/Projects/BigData_Project/data/all_reviews/all_reviews.csv\", header=True, inferSchema=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('hidden_in_steam_china', 'steam_china_location')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 113885601\n"
     ]
    }
   ],
   "source": [
    "# # Count total number of rows\n",
    "# total_rows = df.count()\n",
    "# print(f\"Total number of rows: {total_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recommendationid',\n",
       " 'appid',\n",
       " 'game',\n",
       " 'author_steamid',\n",
       " 'author_num_games_owned',\n",
       " 'author_num_reviews',\n",
       " 'author_playtime_forever',\n",
       " 'author_playtime_last_two_weeks',\n",
       " 'author_playtime_at_review',\n",
       " 'author_last_played',\n",
       " 'language',\n",
       " 'review',\n",
       " 'timestamp_created',\n",
       " 'timestamp_updated',\n",
       " 'voted_up',\n",
       " 'votes_up',\n",
       " 'votes_funny',\n",
       " 'weighted_vote_score',\n",
       " 'comment_count',\n",
       " 'steam_purchase',\n",
       " 'received_for_free',\n",
       " 'written_during_early_access']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.coalesce(1) \\\n",
    "#     .write \\\n",
    "#     .option(\"compression\", \"snappy\") \\\n",
    "#     .parquet(\"D:/STUFF/Projects/BigData_Project/data/all_reviews/new\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import rand\n",
    "\n",
    "# # 1. Load the Parquet file\n",
    "# parquet_input_path = \"D:/STUFF/Projects/BigData_Project/data/all_reviews/main_data.parquet\"\n",
    "# df_parquet = spark.read.parquet(parquet_input_path)\n",
    "\n",
    "# # 2. Print its columns\n",
    "# print(f\"Columns in {parquet_input_path}:\")\n",
    "# print(df_parquet.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample parquet generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load the parquet file\n",
    "# df = spark.read.parquet(\"D:/STUFF/Projects/BigData_Project/data/all_reviews/main_data.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Print the total count to verify data was loaded\n",
    "# total_count = 113885601\n",
    "\n",
    "# # Sample 1 million records randomly\n",
    "# # If the dataset has fewer than 1 million records, we'll take a fraction that would give us 1 million if we had enough\n",
    "# sample_count = 1000000\n",
    "# if total_count > sample_count:\n",
    "#     sampled_df = df.sample(False, sample_count / total_count, seed=42)\n",
    "# else:\n",
    "#     # Take all records if we have fewer than 1 million\n",
    "#     sampled_df = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Verify the count of sampled records\n",
    "# sampled_count = sampled_df.count()\n",
    "# print(f\"Number of sampled records: {sampled_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Save the sampled records as a new parquet file\n",
    "# sampled_df.write \\\n",
    "#     .option(\"compression\", \"snappy\") \\\n",
    "#     .parquet(\"D:/STUFF/Projects/BigData_Project/data/all_reviews/sampled_1m_reviews\")\n",
    "\n",
    "# print(\"Sample parquet file created successfully.\")\n",
    "\n",
    "# # Stop Spark session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled_df.coalesce(1) \\\n",
    "#     .write \\\n",
    "#     .option(\"compression\", \"snappy\") \\\n",
    "#     .parquet(\"D:/STUFF/Projects/BigData_Project/data/all_reviews/sampled_1m_reviews\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample CSV GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: An error occurred while calling o81.pandasStructHandlingMode. Trace:\n",
      "py4j.Py4JException: Method pandasStructHandlingMode([]) does not exist\n",
      "\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:321)\n",
      "\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:329)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:274)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, isnan, count, rand, trim, length\n",
    "from pyspark.sql.types import IntegerType, LongType, BooleanType, FloatType\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "def get_top_10_games_by_reviews(parquet_dir):\n",
    "    \"\"\"\n",
    "    Find the top 10 games with the most reviews from a directory of Parquet files,\n",
    "    grouping by the 'game' column, and display results with a bar chart.\n",
    "    \n",
    "    Parameters:\n",
    "    - parquet_dir: Path to the directory containing Parquet files\n",
    "    \"\"\"\n",
    "    # Initialize Spark session\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"TopGamesByReviews\") \\\n",
    "        .config(\"spark.driver.memory\", \"8g\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    try:\n",
    "        # Load all Parquet files from the directory\n",
    "        df = spark.read.parquet(parquet_dir)\n",
    "        \n",
    "        # Verify if 'game' column exists\n",
    "        if \"game\" not in df.columns:\n",
    "            spark.stop()\n",
    "            raise ValueError(\"Column 'game' not found in the dataset. Available columns: \" + \", \".join(df.columns))\n",
    "        \n",
    "        # Group by 'game', count reviews, and get top 10\n",
    "        top_games = df.groupBy(\"game\") \\\n",
    "                     .count() \\\n",
    "                     .orderBy(col(\"count\").desc()) \\\n",
    "                     .limit(10) \\\n",
    "                     .toPandas()\n",
    "        \n",
    "        # Display results as a table\n",
    "        print(\"Top 10 Games by Review Count:\")\n",
    "        display(top_games)  # Use display for better formatting in Jupyter\n",
    "        \n",
    "        # Create bar chart\n",
    "        fig = px.bar(\n",
    "            top_games,\n",
    "            x=\"game\",\n",
    "            y=\"count\",\n",
    "            title=\"Top 10 Games by Review Count\",\n",
    "            labels={\"game\": \"Game Name\", \"count\": \"Number of Reviews\"},\n",
    "            color=\"game\",\n",
    "            text=\"count\"\n",
    "        )\n",
    "        fig.update_layout(xaxis_tickangle=45, showlegend=False)\n",
    "        fig.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        # Stop Spark session\n",
    "        spark.stop()\n",
    "\n",
    "# Execute the query\n",
    "parquet_dir = \"D:/STUFF/Projects/BigData_Project/data/all_reviews/cleaned_reviews\"\n",
    "get_top_10_games_by_reviews(parquet_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
